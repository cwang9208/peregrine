# Generated by Apache Ambari. Wed Jan 19 06:51:16 2022
    
spark.cores.max 1
spark.driver.cores 1
spark.driver.extraJavaOptions -Dhdp.version= -Detwlogger.component=sparkthriftdriver -DlogFilter.filename=SparkLogFilters.xml -DpatternGroup.filename=SparkPatternGroups.xml -Dlog4jspark.root.logger=INFO,RFA,Anonymizer -Dlog4jspark.log.dir=/var/log/spark -Dlog4jspark.log.file=sparkthriftdriver.log -Djava.io.tmpdir=/var/tmp/spark -Dlog4j.configuration=file:/usr/hdp/current/spark2-client/conf/log4j.properties -Djavax.xml.parsers.SAXParserFactory=com.sun.org.apache.xerces.internal.jaxp.SAXParserFactoryImpl -XX:+UseParallelGC -XX:+UseParallelOldGC
spark.driver.extraLibraryPath /usr/hdp/current/hadoop-client/lib/native:/usr/hdp/current/hadoop-client/lib/native/Linux-amd64-64
spark.driver.memoryOverhead 384
spark.dynamicAllocation.enabled true
spark.dynamicAllocation.executorIdleTimeout 1800s
spark.dynamicAllocation.initialExecutors 0
spark.dynamicAllocation.maxExecutors 1024
spark.dynamicAllocation.minExecutors 0
spark.eventLog.dir wasb:///hdp/spark2-events
spark.eventLog.enabled true
spark.executor.cores 1
spark.executor.extraJavaOptions -Dhdp.version= -Detwlogger.component=sparkthriftexecutor -DlogFilter.filename=SparkLogFilters.xml -DpatternGroup.filename=SparkPatternGroups.xml -Dlog4jspark.root.logger=INFO,RFA,Anonymizer -Dlog4jspark.log.dir=/var/log/spark -Dlog4jspark.log.file=sparkthriftexecutor.log -Djava.io.tmpdir=/var/tmp/spark -Dlog4j.configuration=file:/usr/hdp/current/spark2-client/conf/log4j.properties -Djavax.xml.parsers.SAXParserFactory=com.sun.org.apache.xerces.internal.jaxp.SAXParserFactoryImpl -XX:+UseParallelGC -XX:+UseParallelOldGC
spark.executor.extraLibraryPath /usr/hdp/current/hadoop-client/lib/native:/usr/hdp/current/hadoop-client/lib/native/Linux-amd64-64
spark.executor.memory 3584m
spark.executor.memoryOverhead 384
spark.hadoop.cacheConf false
spark.history.fs.cleaner.enabled true
spark.history.fs.cleaner.interval 7d
spark.history.fs.cleaner.maxAge 90d
spark.history.fs.logDirectory wasb:///hdp/spark2-events
spark.history.provider org.apache.spark.deploy.history.FsHistoryProvider
spark.history.ui.port 18080
spark.io.compression.lz4.blockSize 128kb
spark.locality.wait 0
spark.master yarn
spark.rdd.compress true
spark.scheduler.allocation.file /etc/sparkthrift/conf/sparkThriftFairScheduler.xml
spark.scheduler.mode FAIR
spark.serializer org.apache.spark.serializer.KryoSerializer
spark.shuffle.file.buffer 1m
spark.shuffle.io.backLog 8192
spark.shuffle.io.serverThreads 128
spark.shuffle.service.enabled true
spark.shuffle.unsafe.file.output.buffer 5m
spark.sql.autoBroadcastJoinThreshold 26214400
spark.sql.cbo.enabled true
spark.sql.cbo.joinReorder.enabled true
spark.sql.crossJoin.enabled true
spark.sql.extensions com.microsoft.peregrine.spark.extensions.SparkExtensionsHdi
spark.sql.files.maxPartitionBytes 1073741824
spark.sql.hive.convertMetastoreOrc true
spark.sql.hive.metastore.jars /usr/hdp/4.1.8.19/spark2/standalone-metastore/standalone-metastore-1.21.2.4.1.8.19-hive3.jar
spark.sql.hive.metastore.version 3.0
spark.sql.orc.filterPushdown true
spark.sql.orc.impl native
spark.sql.queryExecutionListeners com.microsoft.peregrine.spark.listeners.PlanLogListener
spark.sql.statistics.fallBackToHdfs true
spark.sql.warehouse.dir /apps/spark/warehouse
spark.ui.port 5040
spark.unsafe.sorter.spill.reader.buffer.size 1m
spark.yarn.am.memory 1g
spark.yarn.containerLauncherMaxThreads 25
spark.yarn.executor.failuresValidityInterval 2h
spark.yarn.jars local:///usr/hdp/current/spark2-client/jars/*
spark.yarn.maxAppAttempts 5
spark.yarn.preserve.staging.files false
spark.yarn.queue thriftsvr
spark.yarn.scheduler.heartbeat.interval-ms 5000
spark.yarn.submit.file.replication 3
    